{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models as models\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_start_method('spawn')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        self.transform = transform\n",
    "        dir_names = os.listdir(path)\n",
    "        dir_names.sort()\n",
    "        self.label_list = []\n",
    "        self.img_list = []\n",
    "        self.file_names = []\n",
    "\n",
    "        for dir_name in dir_names:\n",
    "            if os.path.isdir(os.path.join(path, dir_name)):\n",
    "                self.file_names = os.listdir(os.path.join(path, dir_name))\n",
    "                self.file_names.sort()\n",
    "\n",
    "                for file_name in self.file_names:\n",
    "                    self.img_list.append(Image.fromarray(np.uint8(cv2.imread(os.path.join(path, dir_name, file_name)))))\n",
    "                    self.label_list.append(int(file_name.split('_')[4]))\n",
    "\n",
    "        self.img_transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.img_transform(img)\n",
    "\n",
    "        return img.to(device), label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dataset = EyeDataset(path='/mnt/data/dataset/mrlEyes_2018_01', transform=True)\n",
    "train_size = int(len(dataset)*0.9)\n",
    "val_size = (int(len(dataset)))-train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_data_loader = DataLoader(dataset=train_set, batch_size=10000, num_workers=0)\n",
    "val_data_loader = DataLoader(dataset=val_set, batch_size=10000, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "           Conv2d-15           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "             ReLU-17           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "             ReLU-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
      "           Conv2d-24            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
      "             ReLU-26            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-27            [-1, 128, 8, 8]               0\n",
      "           Conv2d-28            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
      "             ReLU-30            [-1, 128, 8, 8]               0\n",
      "           Conv2d-31            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
      "             ReLU-33            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-34            [-1, 128, 8, 8]               0\n",
      "           Conv2d-35            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 4, 4]             512\n",
      "             ReLU-37            [-1, 256, 4, 4]               0\n",
      "           Conv2d-38            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 4, 4]             512\n",
      "           Conv2d-40            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
      "             ReLU-42            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
      "           Conv2d-44            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 4, 4]             512\n",
      "             ReLU-46            [-1, 256, 4, 4]               0\n",
      "           Conv2d-47            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 4, 4]             512\n",
      "             ReLU-49            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-50            [-1, 256, 4, 4]               0\n",
      "           Conv2d-51            [-1, 512, 2, 2]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-53            [-1, 512, 2, 2]               0\n",
      "           Conv2d-54            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
      "           Conv2d-56            [-1, 512, 2, 2]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-58            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-59            [-1, 512, 2, 2]               0\n",
      "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-62            [-1, 512, 2, 2]               0\n",
      "           Conv2d-63            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-65            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-66            [-1, 512, 2, 2]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.13\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 47.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "summary(model, input_size=(3, 64, 64), device=device.type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████| 8/8 [00:23<00:00,  2.94s/batch, a=0.92, f1=0.93, loss=0.222, p=0.94, r=0.92]\n",
      "Epoch 2/10: 100%|█████████████████████████| 8/8 [00:23<00:00,  2.92s/batch, a=0.97, f1=0.97, loss=0.105, p=0.98, r=0.96]\n",
      "Epoch 3/10: 100%|█████████████████████████| 8/8 [00:21<00:00,  2.70s/batch, a=0.98, f1=0.98, loss=0.065, p=0.99, r=0.97]\n",
      "Epoch 4/10: 100%|█████████████████████████| 8/8 [00:21<00:00,  2.70s/batch, a=0.99, f1=0.99, loss=0.042, p=0.99, r=0.98]\n",
      "Epoch 5/10: 100%|█████████████████████████| 8/8 [00:21<00:00,  2.64s/batch, a=0.99, f1=0.99, loss=0.031, p=0.99, r=0.99]\n",
      "Epoch 6/10: 100%|█████████████████████████| 8/8 [00:21<00:00,  2.63s/batch, a=0.99, f1=0.99, loss=0.026, p=0.99, r=0.99]\n",
      "Epoch 7/10: 100%|█████████████████████████| 8/8 [00:21<00:00,  2.69s/batch, a=0.99, f1=0.99, loss=0.021, p=0.99, r=0.99]\n",
      "Epoch 8/10: 100%|█████████████████████████| 8/8 [00:23<00:00,  2.89s/batch, a=0.99, f1=0.99, loss=0.021, p=1.00, r=0.99]\n",
      "Epoch 9/10: 100%|█████████████████████████| 8/8 [00:21<00:00,  2.64s/batch, a=0.99, f1=0.99, loss=0.019, p=1.00, r=0.99]\n",
      "Epoch 10/10: 100%|████████████████████████| 8/8 [00:21<00:00,  2.68s/batch, a=0.99, f1=0.99, loss=0.020, p=1.00, r=0.99]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    with tqdm(train_data_loader, unit='batch', ncols=120) as tqdm_epochs:\n",
    "        for train_data, train_label in tqdm_epochs:\n",
    "            tqdm_epochs.set_description(f\"Epoch {i+1}/{epochs}\")\n",
    "            outputs = model(train_data)\n",
    "            # 오차 계산\n",
    "            loss = loss_function(outputs, train_label.to(device))\n",
    "\n",
    "            # 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # 역전파\n",
    "            loss.backward()\n",
    "            # 스텝\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted_classes = torch.max(outputs, 1)[1].cpu().numpy()\n",
    "            train_label_cpu = train_label.cpu().numpy()\n",
    "\n",
    "            precision = precision_score(train_label_cpu, predicted_classes, zero_division=0)\n",
    "            recall = recall_score(train_label_cpu, predicted_classes, zero_division=0)\n",
    "            f1 = f1_score(train_label_cpu, predicted_classes, zero_division=0)\n",
    "            accuracy = accuracy_score(train_label_cpu, predicted_classes)\n",
    "\n",
    "            tqdm_epochs.set_postfix(loss=f'{loss.item():.3f}', p=f'{precision:.2f}', r=f'{recall:.2f}', f1=f'{f1:.2f}', a=f'{accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 64, 64])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "img = cv2.imread('/mnt/data/dataset/mrlEyes_2018_01/s0001/s0001_03242_0_1_1_0_1_01.png')\n",
    "img = Image.fromarray(np.uint8(img))\n",
    "input_img = trans(img).unsqueeze(0)\n",
    "input_img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "a = model(input_img.to(device))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.97, recall: 0.99, f1 score: 0.98, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for val_data, val_label in val_data_loader:\n",
    "        outputs = model(val_data)\n",
    "        val_pred = torch.max(outputs, 1)[1].cpu().numpy()\n",
    "        val_label_cpu = val_label.numpy()\n",
    "\n",
    "        precision = precision_score(val_label_cpu, val_pred, zero_division=0)\n",
    "        recall = recall_score(val_label_cpu, val_pred, zero_division=0)\n",
    "        f1 = f1_score(val_label_cpu, val_pred, zero_division=0)\n",
    "        accuracy = accuracy_score(val_label_cpu, val_pred)\n",
    "\n",
    "        print(f'precision: {precision:.2f}, recall: {recall:.2f}, f1 score: {f1:.2f}, accuracy: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './eyes_model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
